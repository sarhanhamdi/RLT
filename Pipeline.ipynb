{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1b2759-11e6-4d78-93f0-7ae17dc7d31f",
   "metadata": {},
   "source": [
    "## 1. Importation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1da962a9-c483-48cc-9336-12347e5c2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df418f0-06b1-41e6-9111-c4147cde2830",
   "metadata": {},
   "source": [
    "## 2. Load Data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4da54eb-1cad-48a1-af96-3308454a52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Le fichier {path} n'existe pas.\")\n",
    "\n",
    "    if not path.endswith(\".csv\"):\n",
    "        raise ValueError(\"Format non support√© : seuls les fichiers .csv sont accept√©s.\")\n",
    "\n",
    "    print(f\"Chargement du dataset : {path}\")\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25635649-3c69-42d3-b70a-ce90bc727be6",
   "metadata": {},
   "source": [
    "## 2. Data Understanding : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4222a5ca-34fb-458a-969e-d27e93c3b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_understanding(df, target_column=None):\n",
    "\n",
    "    print(\"\\nüîπ Shape:\", df.shape)\n",
    "\n",
    "    print(\"\\nüîπ First 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nüîπ Last 5 rows:\")\n",
    "    display(df.tail())\n",
    "\n",
    "    print(\"\\nüîπ Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    print(\"\\nüîπ Data types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\nüîπ Missing values per column:\")\n",
    "    missing_vals = df.isnull().sum()\n",
    "    display(missing_vals[missing_vals > 0])\n",
    "\n",
    "    print(\"\\nüîπ Percentage of missing values per column:\")\n",
    "    missing_percent = (df.isnull().mean() * 100).round(2)\n",
    "    display(missing_percent[missing_percent > 0])\n",
    "\n",
    "    print(\"\\nüîπ Duplicate rows count:\", df.duplicated().sum())\n",
    "    if df.duplicated().sum() > 0:\n",
    "        print(\"üîπ Duplicate rows:\")\n",
    "        display(df[df.duplicated(keep=False)])\n",
    "\n",
    "    print(\"\\nüîπ Target variable preview:\")\n",
    "    if target_column and target_column in df.columns:\n",
    "        display(df[[target_column]].head())\n",
    "    else:\n",
    "        print(\" Target column not found or not provided.\")\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D√©tection des colonnes num√©riques (une seule fois)\n",
    "    # -------------------------------------------------\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    print(\"\\nüîπ Numeric columns:\", list(numeric_cols))\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D√©tection des outliers\n",
    "    # -------------------------------------------------\n",
    "    outlier_counts = {}\n",
    "\n",
    "    if len(numeric_cols) > 0:\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outlier_counts[col] = len(outliers)\n",
    "    else:\n",
    "        print(\"\\n Aucun champ num√©rique ‚Üí impossible de d√©tecter les outliers.\")\n",
    "\n",
    "    print(\"\\nüîπ Number of outliers per numeric column:\")\n",
    "    display(outlier_counts)\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Histogrammes des variables num√©riques\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"\\n Distribution des variables num√©riques :\")\n",
    "        df[numeric_cols].hist(bins=30, figsize=(12, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n Aucun champ num√©rique ‚Üí pas d‚Äôhistogrammes.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Heatmap de corr√©lation\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr = df[numeric_cols].corr().abs()\n",
    "        mask = corr < 0.5\n",
    "\n",
    "        plt.figure(figsize=(18, 14))\n",
    "        ax = sns.heatmap(\n",
    "            corr, mask=mask, cmap=\"coolwarm\", annot=False,\n",
    "            linewidths=0.5, \n",
    "            cbar_kws={'label': 'Force de corr√©lation'}\n",
    "        )\n",
    "\n",
    "        plt.title(\"Heatmap des corr√©lations (seulement |corr| > 0.5)\", fontsize=16)\n",
    "\n",
    "        # L√©gende explicative\n",
    "        plt.text(\n",
    "            x=0.02, y=1.12,\n",
    "            s=(\n",
    "                \"L√©gende des couleurs :\\n\"\n",
    "                \"Rouge fonc√© ‚Üí Corr√©lation tr√®s positive (‚âà 0.8 √† 1.0)\\n\"\n",
    "                \"Bleu fonc√© ‚Üí Corr√©lation tr√®s n√©gative (‚âà -0.8 √† -1.0)\\n\"\n",
    "                \"Blanc ‚Üí Corr√©lation faible (< 0.5) ou masqu√©e\"\n",
    "            ),\n",
    "            fontsize=12,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"white\", ec=\"black\", alpha=0.8)\n",
    "        )\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n Pas assez de colonnes num√©riques pour une heatmap.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Barplot des valeurs manquantes\n",
    "    # -------------------------------------------------\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "\n",
    "    if len(missing) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        missing.sort_values().plot(kind='barh')\n",
    "        plt.title(\"Valeurs manquantes par colonne\")\n",
    "        plt.xlabel(\"Nombre de valeurs manquantes\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n Aucune valeur manquante.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Boxplots pour visualiser les outliers\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 0:\n",
    "        for col in numeric_cols:\n",
    "            if df[col].dropna().nunique() > 1:\n",
    "                plt.figure(figsize=(6, 3))\n",
    "                sns.boxplot(x=df[col])\n",
    "                plt.title(f\"Boxplot ‚Äì {col}\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Impossible de tracer un boxplot pour {col} (pas assez de valeurs).\")\n",
    "    else:\n",
    "        print(\"\\n Aucun champ num√©rique ‚Üí pas de boxplots.\")\n",
    "\n",
    "\n",
    "    return outlier_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3aaa45-8b3b-4693-85f7-1c924241c638",
   "metadata": {},
   "source": [
    "## 3. Data Preperation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ed6ae-5d77-4c8b-abea-79669b5bb527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "823e2171-78b6-4396-afab-da8a4f5c48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(df, target_column, task=\"classification\", apply_capping=True):\n",
    "    df = df.copy()\n",
    "    original_shape = df.shape\n",
    "\n",
    "    # Supprimer colonnes 100% NaN\n",
    "    nan_cols = [c for c in df.columns if c != target_column and df[c].isna().all()]\n",
    "    df.drop(columns=nan_cols, inplace=True)\n",
    "    df = df.dropna(subset=[target_column])\n",
    "\n",
    "    # S√©paration X / y\n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=[target_column])\n",
    "\n",
    "    # D√©tection types\n",
    "    numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # Traitement capping\n",
    "    if apply_capping and numeric_cols:\n",
    "        X = cap_iqr_df(X, numeric_cols)\n",
    "\n",
    "    # Suppression variance nulle\n",
    "    zero_var_cols = []\n",
    "    if numeric_cols:\n",
    "        selector = VarianceThreshold(0.0)\n",
    "        selector.fit(X[numeric_cols])\n",
    "        zero_var_cols = [col for col, keep in zip(numeric_cols, selector.get_support()) if not keep]\n",
    "        X.drop(columns=zero_var_cols, inplace=True)\n",
    "        numeric_cols = [c for c in numeric_cols if c not in zero_var_cols]\n",
    "\n",
    "    # Pipelines num√©riques et cat√©gorielles\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "    X_prepared = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Encodage cible\n",
    "    label_encoder = None\n",
    "    if task == \"classification\":\n",
    "        if y.dtype == \"object\" or y.dtype.name == \"category\":\n",
    "            label_encoder = LabelEncoder()\n",
    "            y_final = label_encoder.fit_transform(y)\n",
    "        else:\n",
    "            y_final = y.values\n",
    "    elif task == \"regression\":\n",
    "        y_final = y.values.astype(float)\n",
    "\n",
    "    # Dataset nettoy√© final\n",
    "    df_clean = pd.concat([X.reset_index(drop=True), y.reset_index(drop=True)], axis=1)\n",
    "\n",
    "    return X_prepared, y_final, preprocessor, df_clean, label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "964e3a3b-59de-42e3-98f0-f93dfecdc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_dataset(name, df_clean, folder=\"clean_datasets\", n_rows=150, random=True):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    path = os.path.join(folder, f\"{name}_clean.csv\")\n",
    "    \n",
    "    df_to_save = (\n",
    "        df_clean.sample(n=min(n_rows, len(df_clean)), random_state=42)\n",
    "        if random else\n",
    "        df_clean.head(n_rows)\n",
    "    )\n",
    "    \n",
    "    df_to_save.to_csv(path, index=False)\n",
    "    print(f\" Dataset sauvegard√© ({len(df_to_save)} observations) : {path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc809d3e-223d-4d57-b5a9-fe8d027842af",
   "metadata": {},
   "source": [
    "## 4. Modeling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd41eb-317a-455e-b1e7-d45d4e6750ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4cc4be-a854-48b7-8971-21e8cd71539e",
   "metadata": {},
   "source": [
    "## 5. Evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c50b3b-3287-4023-84dc-867532a4f4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "466fdb31-c9ed-4126-bc67-8b71e96142a4",
   "metadata": {},
   "source": [
    "## 6. Deploiment : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfce170-a7cb-42a4-9a02-ad212b24d07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
