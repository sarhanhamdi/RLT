{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad22f54-9fb2-4e5f-9228-c9d1a1ef0638",
   "metadata": {},
   "source": [
    "## 1. Importation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca55584-ad6e-4a75-b66b-4e278c62521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53fc613-3db6-4eaf-9861-8ef09c96d765",
   "metadata": {},
   "source": [
    "## 2. Load Data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640eb2ed-8df4-4958-ac7c-762cadc0fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Le fichier {path} n'existe pas.\")\n",
    "\n",
    "    if not path.endswith(\".csv\"):\n",
    "        raise ValueError(\"Format non support√© : seuls les fichiers .csv sont accept√©s.\")\n",
    "\n",
    "    print(f\"Chargement du dataset : {path}\")\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8e1bc4-caec-488e-80e0-5169686dbb6a",
   "metadata": {},
   "source": [
    "## 2. Data Understanding : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbf7f3b3-70d5-4f72-a83d-3a2f400ad3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_understanding(df, target_column=None):\n",
    "\n",
    "    print(\"\\nüîπ Shape:\", df.shape)\n",
    "\n",
    "    print(\"\\nüîπ First 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nüîπ Last 5 rows:\")\n",
    "    display(df.tail())\n",
    "\n",
    "    print(\"\\nüîπ Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    print(\"\\nüîπ Data types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\nüîπ Missing values per column:\")\n",
    "    missing_vals = df.isnull().sum()\n",
    "    display(missing_vals[missing_vals > 0])\n",
    "\n",
    "    print(\"\\nüîπ Percentage of missing values per column:\")\n",
    "    missing_percent = (df.isnull().mean() * 100).round(2)\n",
    "    display(missing_percent[missing_percent > 0])\n",
    "\n",
    "    print(\"\\nüîπ Duplicate rows count:\", df.duplicated().sum())\n",
    "    if df.duplicated().sum() > 0:\n",
    "        print(\"üîπ Duplicate rows:\")\n",
    "        display(df[df.duplicated(keep=False)])\n",
    "\n",
    "    print(\"\\nüîπ Target variable preview:\")\n",
    "    if target_column and target_column in df.columns:\n",
    "        display(df[[target_column]].head())\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Target column not found or not provided.\")\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D√©tection des colonnes num√©riques (une seule fois)\n",
    "    # -------------------------------------------------\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    print(\"\\nüîπ Numeric columns:\", list(numeric_cols))\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D√©tection des outliers\n",
    "    # -------------------------------------------------\n",
    "    outlier_counts = {}\n",
    "\n",
    "    if len(numeric_cols) > 0:\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outlier_counts[col] = len(outliers)\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Aucun champ num√©rique ‚Üí impossible de d√©tecter les outliers.\")\n",
    "\n",
    "    print(\"\\nüîπ Number of outliers per numeric column:\")\n",
    "    display(outlier_counts)\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Histogrammes des variables num√©riques\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"\\nüìä Distribution des variables num√©riques :\")\n",
    "        df[numeric_cols].hist(bins=30, figsize=(12, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Aucun champ num√©rique ‚Üí pas d‚Äôhistogrammes.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Heatmap de corr√©lation\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr = df[numeric_cols].corr().abs()\n",
    "        mask = corr < 0.5\n",
    "\n",
    "        plt.figure(figsize=(18, 14))\n",
    "        ax = sns.heatmap(\n",
    "            corr, mask=mask, cmap=\"coolwarm\", annot=False,\n",
    "            linewidths=0.5, \n",
    "            cbar_kws={'label': 'Force de corr√©lation'}\n",
    "        )\n",
    "\n",
    "        plt.title(\"Heatmap des corr√©lations (seulement |corr| > 0.5)\", fontsize=16)\n",
    "\n",
    "        # L√©gende explicative\n",
    "        plt.text(\n",
    "            x=0.02, y=1.12,\n",
    "            s=(\n",
    "                \"L√©gende des couleurs :\\n\"\n",
    "                \"Rouge fonc√© ‚Üí Corr√©lation tr√®s positive (‚âà 0.8 √† 1.0)\\n\"\n",
    "                \"Bleu fonc√© ‚Üí Corr√©lation tr√®s n√©gative (‚âà -0.8 √† -1.0)\\n\"\n",
    "                \"Blanc ‚Üí Corr√©lation faible (< 0.5) ou masqu√©e\"\n",
    "            ),\n",
    "            fontsize=12,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"white\", ec=\"black\", alpha=0.8)\n",
    "        )\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Pas assez de colonnes num√©riques pour une heatmap.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Barplot des valeurs manquantes\n",
    "    # -------------------------------------------------\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "\n",
    "    if len(missing) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        missing.sort_values().plot(kind='barh')\n",
    "        plt.title(\"Valeurs manquantes par colonne\")\n",
    "        plt.xlabel(\"Nombre de valeurs manquantes\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nAucune valeur manquante.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Boxplots pour visualiser les outliers\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 0:\n",
    "        for col in numeric_cols:\n",
    "            if df[col].dropna().nunique() > 1:\n",
    "                plt.figure(figsize=(6, 3))\n",
    "                sns.boxplot(x=df[col])\n",
    "                plt.title(f\"Boxplot ‚Äì {col}\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Impossible de tracer un boxplot pour {col} (pas assez de valeurs).\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Aucun champ num√©rique ‚Üí pas de boxplots.\")\n",
    "\n",
    "\n",
    "    return outlier_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da9889-3bf7-4409-b22c-e0a385531492",
   "metadata": {},
   "source": [
    "## 3. Data Preperation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e1ac02-d859-4274-9262-335a4e1d7d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_iqr(df, numeric_columns, factor=1.5):\n",
    "    df = df.copy()\n",
    "    for col in numeric_columns:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        \n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower = Q1 - factor * IQR\n",
    "        upper = Q3 + factor * IQR\n",
    "        \n",
    "        df[col] = np.where(df[col] < lower, lower, df[col])\n",
    "        df[col] = np.where(df[col] > upper, upper, df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def data_preparation(df, target_column, apply_capping=False):\n",
    "    df = df.copy()\n",
    "    original_cols = df.columns.tolist()\n",
    "    original_shape = df.shape\n",
    "\n",
    "    # 1) Remove columns 100% NaN (except target)\n",
    "    cols_to_drop = [col for col in df.columns \n",
    "                    if col != target_column and df[col].isna().all()]\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "    # 2) Remove zero variance columns\n",
    "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    numeric_cols_no_target = [col for col in numeric_cols if col != target_column]\n",
    "\n",
    "    zero_var_cols = []\n",
    "    if numeric_cols_no_target:\n",
    "        selector = VarianceThreshold(threshold=0.0)\n",
    "        selector.fit(df[numeric_cols_no_target])\n",
    "        zero_var_cols = [col for col, keep in zip(numeric_cols_no_target,\n",
    "                                                  selector.get_support())\n",
    "                         if not keep]\n",
    "        df = df.drop(columns=zero_var_cols)\n",
    "\n",
    "    # Ensure target exists\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_column}' was removed!\")\n",
    "\n",
    "    # 3) Separate target\n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=[target_column])\n",
    "\n",
    "    # Detect column types\n",
    "    numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # 4) Apply IQR capping\n",
    "    if apply_capping:\n",
    "        X = cap_iqr(X, numeric_cols)\n",
    "\n",
    "    # 5) Build pipeline\n",
    "    numeric_pipeline = Pipeline([(\"scaler\", StandardScaler())])\n",
    "    categorical_pipeline = Pipeline([(\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_prepared = preprocessor.fit_transform(X)\n",
    "\n",
    "    # Output summary\n",
    "    print(\"\\n=== DATA PREPARATION SUMMARY ===\")\n",
    "    print(f\"Shape before preparation: {original_shape}\")\n",
    "    print(f\"Shape after preparation: {df.shape}\")\n",
    "    print(f\"Columns removed: {cols_to_drop + zero_var_cols}\")\n",
    "\n",
    "    print(\"\\nTarget preview:\")\n",
    "    display(y.head())\n",
    "\n",
    "    print(\"\\nX (before preprocessing):\")\n",
    "    display(X.head())\n",
    "\n",
    "    print(\"\\nX_prepared shape:\", X_prepared.shape)\n",
    "    print(\"\\nPreprocessor used:\")\n",
    "    print(preprocessor)\n",
    "\n",
    "    removed_cols = cols_to_drop + zero_var_cols\n",
    "\n",
    "    return X, X_prepared, y, preprocessor, removed_cols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1fc71-f433-4907-bb6c-b16cc6513560",
   "metadata": {},
   "source": [
    "## 4. Modeling :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73bea0b-ce50-434a-bae6-d12bd016882b",
   "metadata": {},
   "source": [
    "##  Regression :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b33c6b8d-172f-416f-badf-bc6f9c18c4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "\n",
    "\n",
    "def run_regression_models(X, y, preprocessor, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Pipeline complet pour entra√Æner plusieurs mod√®les de r√©gression\n",
    "    et retourner leurs scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Liste des mod√®les\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestRegressor(random_state=42),\n",
    "        \"ExtraTrees\": ExtraTreesRegressor(random_state=42),\n",
    "        \"GradientBoosting\": GradientBoostingRegressor(random_state=42),\n",
    "        # \"RLT_Regressor\": RLTRegressor(...)  # √Ä ajouter si RLT dispo\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        reg = Pipeline([\n",
    "            (\"preprocessing\", preprocessor),\n",
    "            (\"regressor\", model)\n",
    "        ])\n",
    "\n",
    "        # Train\n",
    "        reg.fit(X_train, y_train)\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        # Metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mse ** 0.5\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "        results[model_name] = {\n",
    "            \"RMSE\": round(rmse, 4),\n",
    "            \"MSE\": round(mse, 4),\n",
    "            \"R2-score\": round(r2, 4)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da643842-2d4c-4fff-9431-4d0bede26dff",
   "metadata": {},
   "source": [
    "##  Classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01cce4be-d322-4cfc-bf5b-a98cd0341562",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier\n",
    ")\n",
    "\n",
    "\n",
    "def run_classification_models(X, y, preprocessor, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Pipeline complet pour entra√Æner plusieurs mod√®les de classification\n",
    "    et retourner leurs scores.\n",
    "    \"\"\"\n",
    "\n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "\n",
    "    # Liste des mod√®les √† tester\n",
    "    models = {\n",
    "        \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(random_state=42),\n",
    "        \"GradientBoosting\": GradientBoostingClassifier(random_state=42),\n",
    "        # \"RLT_Classifier\": RLTClassifier(...)   # √Ä ajouter si tu impl√©mentes RLT\n",
    "    }\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "\n",
    "        clf = Pipeline([\n",
    "            (\"preprocessing\", preprocessor),\n",
    "            (\"classifier\", model)\n",
    "        ])\n",
    "\n",
    "        # Fit\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Scores\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "        try:\n",
    "            y_prob = clf.predict_proba(X_test)[:, 1]\n",
    "            auc = roc_auc_score(y_test, y_prob)\n",
    "        except:\n",
    "            auc = \"N/A\"\n",
    "\n",
    "        results[model_name] = {\n",
    "            \"Accuracy\": round(acc, 4),\n",
    "            \"F1-score\": round(f1, 4),\n",
    "            \"ROC-AUC\": auc if auc == \"N/A\" else round(auc, 4)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a11f2f-7e34-415f-b666-222876f7e2f9",
   "metadata": {},
   "source": [
    "##  RLT :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87a4ebe8-6a86-4e91-a96e-37c1738da4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rlt_model(X, y, preprocessor, task=\"regression\", test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Pipeline pour entra√Æner un mod√®le RLT (regression ou classification)\n",
    "    et calculer les m√©triques.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state,\n",
    "        stratify=y if task==\"classification\" else None\n",
    "    )\n",
    "\n",
    "    # Initialisation du mod√®le RLT (√† remplacer par ton impl√©mentation Python)\n",
    "    if task==\"regression\":\n",
    "        model = RLTRegressor(ntrees=100, nmin=2, muting_rate=0.5, k=2, alpha=0.25)\n",
    "    else:\n",
    "        model = RLTClassifier(ntrees=100, nmin=2, muting_rate=0.5, k=2, alpha=0.25)\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"preprocessing\", preprocessor),\n",
    "        (\"rlt\", model)\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "\n",
    "    if task==\"regression\":\n",
    "        from sklearn.metrics import mean_squared_error, r2_score\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = mse ** 0.5\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        metrics = {\"RMSE\": round(rmse, 4), \"R2\": round(r2,4)}\n",
    "    else:\n",
    "        from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "        try:\n",
    "            y_prob = pipe.predict_proba(X_test)[:,1]\n",
    "            auc = round(roc_auc_score(y_test, y_prob),4)\n",
    "        except:\n",
    "            auc = \"N/A\"\n",
    "        metrics = {\n",
    "            \"Accuracy\": round(accuracy_score(y_test, y_pred),4),\n",
    "            \"F1-score\": round(f1_score(y_test, y_pred, average=\"weighted\"),4),\n",
    "            \"ROC-AUC\": auc\n",
    "        }\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082fa3d-b297-4cb9-a141-dbf826ae070e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
