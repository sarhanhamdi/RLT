{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1b2759-11e6-4d78-93f0-7ae17dc7d31f",
   "metadata": {},
   "source": [
    "## 1. Importation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1da962a9-c483-48cc-9336-12347e5c2125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, ExtraTreesRegressor, ExtraTreesClassifier, GradientBoostingRegressor, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df418f0-06b1-41e6-9111-c4147cde2830",
   "metadata": {},
   "source": [
    "## 2. Load Data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4da54eb-1cad-48a1-af96-3308454a52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Le fichier {path} n'existe pas.\")\n",
    "\n",
    "    if not path.endswith(\".csv\"):\n",
    "        raise ValueError(\"Format non support√© : seuls les fichiers .csv sont accept√©s.\")\n",
    "\n",
    "    print(f\"Chargement du dataset : {path}\")\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25635649-3c69-42d3-b70a-ce90bc727be6",
   "metadata": {},
   "source": [
    "## 2. Data Understanding : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4222a5ca-34fb-458a-969e-d27e93c3b2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_understanding(df, target_column=None):\n",
    "\n",
    "    print(\"\\nüîπ Shape:\", df.shape)\n",
    "\n",
    "    print(\"\\nüîπ First 5 rows:\")\n",
    "    display(df.head())\n",
    "\n",
    "    print(\"\\nüîπ Last 5 rows:\")\n",
    "    display(df.tail())\n",
    "\n",
    "    print(\"\\nüîπ Info:\")\n",
    "    print(df.info())\n",
    "\n",
    "    print(\"\\nüîπ Data types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\nüîπ Missing values per column:\")\n",
    "    missing_vals = df.isnull().sum()\n",
    "    display(missing_vals[missing_vals > 0])\n",
    "\n",
    "    print(\"\\nüîπ Percentage of missing values per column:\")\n",
    "    missing_percent = (df.isnull().mean() * 100).round(2)\n",
    "    display(missing_percent[missing_percent > 0])\n",
    "\n",
    "    print(\"\\nüîπ Duplicate rows count:\", df.duplicated().sum())\n",
    "    if df.duplicated().sum() > 0:\n",
    "        print(\"üîπ Duplicate rows:\")\n",
    "        display(df[df.duplicated(keep=False)])\n",
    "\n",
    "    print(\"\\nüîπ Target variable preview:\")\n",
    "    if target_column and target_column in df.columns:\n",
    "        display(df[[target_column]].head())\n",
    "    else:\n",
    "        print(\" Target column not found or not provided.\")\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D√©tection des colonnes num√©riques (une seule fois)\n",
    "    # -------------------------------------------------\n",
    "    numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    print(\"\\nüîπ Numeric columns:\", list(numeric_cols))\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # D√©tection des outliers\n",
    "    # -------------------------------------------------\n",
    "    outlier_counts = {}\n",
    "\n",
    "    if len(numeric_cols) > 0:\n",
    "        for col in numeric_cols:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "            outlier_counts[col] = len(outliers)\n",
    "    else:\n",
    "        print(\"\\n Aucun champ num√©rique ‚Üí impossible de d√©tecter les outliers.\")\n",
    "\n",
    "    print(\"\\nüîπ Number of outliers per numeric column:\")\n",
    "    display(outlier_counts)\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Histogrammes des variables num√©riques\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 0:\n",
    "        print(\"\\n Distribution des variables num√©riques :\")\n",
    "        df[numeric_cols].hist(bins=30, figsize=(12, 8))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n Aucun champ num√©rique ‚Üí pas d‚Äôhistogrammes.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Heatmap de corr√©lation\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 1:\n",
    "        corr = df[numeric_cols].corr().abs()\n",
    "        mask = corr < 0.5\n",
    "\n",
    "        plt.figure(figsize=(18, 14))\n",
    "        ax = sns.heatmap(\n",
    "            corr, mask=mask, cmap=\"coolwarm\", annot=False,\n",
    "            linewidths=0.5, \n",
    "            cbar_kws={'label': 'Force de corr√©lation'}\n",
    "        )\n",
    "\n",
    "        plt.title(\"Heatmap des corr√©lations (seulement |corr| > 0.5)\", fontsize=16)\n",
    "\n",
    "        # L√©gende explicative\n",
    "        plt.text(\n",
    "            x=0.02, y=1.12,\n",
    "            s=(\n",
    "                \"L√©gende des couleurs :\\n\"\n",
    "                \"Rouge fonc√© ‚Üí Corr√©lation tr√®s positive (‚âà 0.8 √† 1.0)\\n\"\n",
    "                \"Bleu fonc√© ‚Üí Corr√©lation tr√®s n√©gative (‚âà -0.8 √† -1.0)\\n\"\n",
    "                \"Blanc ‚Üí Corr√©lation faible (< 0.5) ou masqu√©e\"\n",
    "            ),\n",
    "            fontsize=12,\n",
    "            transform=ax.transAxes,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle=\"round,pad=0.4\", fc=\"white\", ec=\"black\", alpha=0.8)\n",
    "        )\n",
    "\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n Pas assez de colonnes num√©riques pour une heatmap.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Barplot des valeurs manquantes\n",
    "    # -------------------------------------------------\n",
    "    missing = df.isnull().sum()\n",
    "    missing = missing[missing > 0]\n",
    "\n",
    "    if len(missing) > 0:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        missing.sort_values().plot(kind='barh')\n",
    "        plt.title(\"Valeurs manquantes par colonne\")\n",
    "        plt.xlabel(\"Nombre de valeurs manquantes\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n Aucune valeur manquante.\")\n",
    "\n",
    "\n",
    "\n",
    "    # -------------------------------------------------\n",
    "    # Boxplots pour visualiser les outliers\n",
    "    # -------------------------------------------------\n",
    "    if len(numeric_cols) > 0:\n",
    "        for col in numeric_cols:\n",
    "            if df[col].dropna().nunique() > 1:\n",
    "                plt.figure(figsize=(6, 3))\n",
    "                sns.boxplot(x=df[col])\n",
    "                plt.title(f\"Boxplot ‚Äì {col}\")\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Impossible de tracer un boxplot pour {col} (pas assez de valeurs).\")\n",
    "    else:\n",
    "        print(\"\\n Aucun champ num√©rique ‚Üí pas de boxplots.\")\n",
    "\n",
    "\n",
    "    return outlier_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3aaa45-8b3b-4693-85f7-1c924241c638",
   "metadata": {},
   "source": [
    "## 3. Data Preperation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9eed9241-b366-454d-9207-fd6921f8daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_iqr(df, numeric_columns, factor=1.5):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "\n",
    "        if IQR == 0 or np.isnan(IQR):\n",
    "            continue\n",
    "\n",
    "        lower = Q1 - factor * IQR\n",
    "        upper = Q3 + factor * IQR\n",
    "\n",
    "        df[col] = np.clip(df[col], lower, upper)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def data_preparation(df, target_column, apply_capping=True):\n",
    "    df = df.copy()\n",
    "    original_shape = df.shape\n",
    "\n",
    "    # =============================\n",
    "    # 1) Supprimer colonnes 100% NaN\n",
    "    # =============================\n",
    "    nan_cols = [\n",
    "        col for col in df.columns\n",
    "        if col != target_column and df[col].isna().all()\n",
    "    ]\n",
    "    df.drop(columns=nan_cols, inplace=True)\n",
    "\n",
    "    # =============================\n",
    "    # 2) Supprimer variance nulle\n",
    "    # =============================\n",
    "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    numeric_cols = [c for c in numeric_cols if c != target_column]\n",
    "\n",
    "    zero_var_cols = []\n",
    "    if numeric_cols:\n",
    "        selector = VarianceThreshold(0.0)\n",
    "        selector.fit(df[numeric_cols])\n",
    "        zero_var_cols = [\n",
    "            col for col, keep in zip(numeric_cols, selector.get_support())\n",
    "            if not keep\n",
    "        ]\n",
    "        df.drop(columns=zero_var_cols, inplace=True)\n",
    "\n",
    "    # =============================\n",
    "    # 3) S√©paration X / y\n",
    "    # =============================\n",
    "    if target_column not in df.columns:\n",
    "        raise ValueError(f\"Target '{target_column}' supprim√©e par erreur\")\n",
    "\n",
    "    y = df[target_column]\n",
    "    X = df.drop(columns=[target_column])\n",
    "\n",
    "    # =============================\n",
    "    # 4) D√©tection types\n",
    "    # =============================\n",
    "    numeric_cols = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "\n",
    "    # =============================\n",
    "    # 5) Capping IQR\n",
    "    # =============================\n",
    "    if apply_capping and numeric_cols:\n",
    "        X = cap_iqr(X, numeric_cols)\n",
    "\n",
    "    # =============================\n",
    "    # 6) Pipeline sklearn\n",
    "    # =============================\n",
    "    numeric_pipeline = Pipeline([\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_pipeline = Pipeline([\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    X_prepared = preprocessor.fit_transform(X)\n",
    "\n",
    "    # =============================\n",
    "    # 7) Dataset nettoy√© final\n",
    "    # =============================\n",
    "    df_clean = pd.concat(\n",
    "        [X.reset_index(drop=True), y.reset_index(drop=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # =============================\n",
    "    # 8) R√©sum√©\n",
    "    # =============================\n",
    "    print(\"\\n=== DATA PREPARATION SUMMARY ===\")\n",
    "    print(f\"Shape initiale : {original_shape}\")\n",
    "    print(f\"Shape finale   : {df_clean.shape}\")\n",
    "    print(f\"Colonnes supprim√©es : {nan_cols + zero_var_cols}\")\n",
    "    print(f\"Features num√©riques : {len(numeric_cols)}\")\n",
    "    print(f\"Features cat√©gorielles : {len(categorical_cols)}\")\n",
    "    print(f\"X_prepared shape : {X_prepared.shape}\")\n",
    "\n",
    "    return X, X_prepared, y, preprocessor, nan_cols + zero_var_cols, df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "964e3a3b-59de-42e3-98f0-f93dfecdc60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_dataset(name, df_clean, folder=\"clean_datasets\"):\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    path = os.path.join(folder, f\"{name}_clean.csv\")\n",
    "    df_clean.to_csv(path, index=False)\n",
    "    print(f\" Dataset sauvegard√© : {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc809d3e-223d-4d57-b5a9-fe8d027842af",
   "metadata": {},
   "source": [
    "## 4. Modeling :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63cd41eb-317a-455e-b1e7-d45d4e6750ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af4cc4be-a854-48b7-8971-21e8cd71539e",
   "metadata": {},
   "source": [
    "## 5. Evaluation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c50b3b-3287-4023-84dc-867532a4f4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "466fdb31-c9ed-4126-bc67-8b71e96142a4",
   "metadata": {},
   "source": [
    "## 6. Deploiment : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfce170-a7cb-42a4-9a02-ad212b24d07a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
