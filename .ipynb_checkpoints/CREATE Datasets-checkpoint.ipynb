{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d2632a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00bdfc88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>task_type</th>\n",
       "      <th>model</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>scenario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toy</td>\n",
       "      <td>regression</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>MSE</td>\n",
       "      <td>1.881405</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toy</td>\n",
       "      <td>regression</td>\n",
       "      <td>RLT</td>\n",
       "      <td>MSE</td>\n",
       "      <td>14.804511</td>\n",
       "      <td>scenario1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset   task_type         model metric      value   scenario\n",
       "0     toy  regression  RandomForest    MSE   1.881405  scenario1\n",
       "1     toy  regression           RLT    MSE  14.804511  scenario1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"results/metrics_regression.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc65dc6-e083-4fe5-af5e-9c38f94e6eaa",
   "metadata": {},
   "source": [
    "on g√©n√®re un probl√®me de classification binaire o√π les variables explicatives sont ind√©pendantes et uniformes entre 0 et 1.\n",
    "La probabilit√© que Y=1 d√©pend de mani√®re non-lin√©aire des deux premi√®res variables, et on utilise la fonction de r√©partition normale pour transformer cette combinaison en une probabilit√© entre 0 et 1.\n",
    "enfin, on g√©n√®re la classe Y √† partir d‚Äôune loi Bernoulli.\n",
    "Ce sc√©nario permet de tester des m√©thodes de classification dans un cadre simple mais non-lin√©aire.\n",
    "X[:,0] = ùëã ( 1 )\n",
    "X[:,1] = ùëã ( 2 ) \n",
    "norm.cdf() = fonction Œ¶ (CDF normale standard)\n",
    "Pourquoi utiliser une CDF normale ?\n",
    "Pour obtenir des probabilit√©s dans [0,1] √† partir d‚Äôune combinaison lin√©aire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2187fe89-de1c-4c4a-bd80-bc893aa1279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as dataset_scenario1.csv\n",
      "         X1        X2            mu  Y\n",
      "0  0.705134  0.702707  8.655238e-01  1\n",
      "1  0.245582  0.370468  3.643706e-07  0\n",
      "2  0.684008  0.572693  4.399819e-02  0\n",
      "3  0.240366  0.659481  5.247460e-06  0\n",
      "4  0.150357  0.728866  4.443904e-05  0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Parameters\n",
    "N = 100\n",
    "p = 2  # at least 2 variables required\n",
    "\n",
    "# Generate X ~ Unif[0,1]^p\n",
    "X = np.random.uniform(0, 1, size=(N, p))\n",
    "\n",
    "# Compute mu_i = Œ¶(10 * (X1 - 1) + 20 * |X2 - 0.5|)\n",
    "mu = norm.cdf(10 * (X[:,0] - 1) + 20 * np.abs(X[:,1] - 0.5))\n",
    "\n",
    "# Generate Y_i ~ Bernoulli(mu_i)\n",
    "Y = np.random.binomial(1, mu)\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"X1\": X[:,0],\n",
    "    \"X2\": X[:,1],\n",
    "    \"mu\": mu,\n",
    "    \"Y\": Y\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"dataset_scenario1.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as dataset_scenario1.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0072f4-250c-4c7d-aff7-6be5bdf5beea",
   "metadata": {},
   "source": [
    "on g√©n√®re un mod√®le de r√©gression non lin√©aire o√π les variables explicatives sont ind√©pendantes et uniformes entre 0 et 1.\n",
    "La r√©ponse d√©pend uniquement des deux premi√®res variables, √† travers des termes tronqu√©s (parties positives), ce qui cr√©e une relation active seulement lorsque ùëã ( 1 ) > 0.5 X (1) >0.5 et ùëã ( 2 ) > 0.25 X (2) >0.25.\n",
    "Cette structure introduit une non-lin√©arit√© forte, car la fonction s‚Äôannule pour une grande partie de l‚Äôespace des covariables, puis augmente rapidement ailleurs.\n",
    "enfin, on ajoute un bruit gaussien pour simuler une r√©ponse r√©elle.\n",
    "np.maximum(a,0) = ( ùëé ) + \n",
    "(a) + = partie positive \n",
    "pourquoi la partie positive ? ‚Üí Pour cr√©er une fonction non lin√©aire qui s‚Äôactive seulement au-del√† d‚Äôun certain seuil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7a5665-a57a-4475-9213-b70ca0d20bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as dataset_scenario2.csv\n",
      "         X1        X2         Y\n",
      "0  0.319322  0.951037  1.148355\n",
      "1  0.755862  0.344935 -0.217128\n",
      "2  0.230846  0.424519  0.496688\n",
      "3  0.427327  0.472000  1.590026\n",
      "4  0.385562  0.995382  0.800516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "N = 100      # number of samples\n",
    "p = 2        # dimensionality (we need at least 2)\n",
    "\n",
    "# Generate X ~ Unif[0,1]^p\n",
    "X = np.random.uniform(0, 1, size=(N, p))\n",
    "\n",
    "# Noise\n",
    "epsilon = np.random.normal(0, 1, size=N)\n",
    "\n",
    "# Compute Y according to the model\n",
    "# (x)^+ means max(x,0)\n",
    "Y = 100 * np.maximum(X[:,0] - 0.5, 0)**2 * np.maximum(X[:,1] - 0.25, 0) + epsilon\n",
    "\n",
    "# Build DataFrame\n",
    "df = pd.DataFrame({\n",
    "    \"X1\": X[:,0],\n",
    "    \"X2\": X[:,1],\n",
    "    \"Y\": Y\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"dataset_scenario2.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as dataset_scenario2.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32fab9f5-a6e5-4316-a3fd-855a06c64b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as dataset_scenario3.csv\n",
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0 -0.688638 -1.066375 -0.460146 -0.059467 -0.271955 -0.131493 -0.788809   \n",
      "1 -0.411813  0.034179 -0.227969  0.325822 -0.036876 -0.413824 -0.498281   \n",
      "2  1.008238  0.459569  0.491861  0.453412  0.755115 -0.096177 -0.658120   \n",
      "3 -1.746562 -1.327608 -1.011336 -0.806175 -1.226004 -0.725211 -0.701643   \n",
      "4 -0.604899 -0.530167 -0.014808  0.324090 -0.093750 -0.582721 -0.062468   \n",
      "\n",
      "         X8        X9       X10  ...      X192      X193      X194      X195  \\\n",
      "0 -0.737242 -1.156370 -1.482951  ...  0.450268 -0.098392  0.613270  0.891197   \n",
      "1 -1.501095 -1.305745 -1.319844  ...  0.039779 -0.119592 -0.389605 -0.519751   \n",
      "2 -0.480647  0.068644  0.200754  ...  1.318274  0.917366  0.661210  1.119629   \n",
      "3 -0.712942 -0.444518 -0.075309  ...  2.288081  2.320963  1.992203  2.211537   \n",
      "4  0.206996  0.427822  0.499930  ... -0.171055  0.393061  0.880157  0.091806   \n",
      "\n",
      "       X196      X197      X198      X199      X200          Y  \n",
      "0  0.406369  0.388929  0.231774  0.289171  0.376320  -0.187379  \n",
      "1 -0.695257 -0.377333 -0.424706 -0.110568 -0.322028   0.726299  \n",
      "2  1.148519  1.645208  1.303476  1.079010  1.954978   6.774631  \n",
      "3  2.409438  2.931772  2.752969  2.670755  3.139372  11.331977  \n",
      "4  0.205028  0.377595  0.408064 -0.414781 -0.071953   0.050559  \n",
      "\n",
      "[5 rows x 201 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "N = 300\n",
    "p = 200  # must be >= 200\n",
    "\n",
    "# Build covariance matrix Œ£_ij = 0.9^{|i-j|}\n",
    "rho = 0.9\n",
    "indices = np.arange(p)\n",
    "Sigma = rho ** np.abs(indices.reshape(-1, 1) - indices.reshape(1, -1))\n",
    "\n",
    "# Generate X ~ N(0, Œ£)\n",
    "X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma, size=N)\n",
    "\n",
    "# Noise\n",
    "epsilon = np.random.normal(0, 1, size=N)\n",
    "\n",
    "# Compute Y = 2 X50 X100 + 2 X150 X200 + noise\n",
    "Y = (\n",
    "    2 * X[:, 49] * X[:, 99] +   # X^(50) * X^(100)\n",
    "    2 * X[:, 149] * X[:, 199] + # X^(150) * X^(200)\n",
    "    epsilon\n",
    ")\n",
    "\n",
    "# Build DataFrame with X1,...,Xp\n",
    "df = pd.DataFrame(X, columns=[f\"X{i+1}\" for i in range(p)])\n",
    "df[\"Y\"] = Y\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"dataset_scenario3.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as dataset_scenario3.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9327d2dc-ca96-42f4-a41f-503c8ab8cd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as dataset_scenario4.csv\n",
      "         X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0 -0.251218  0.753262 -0.292834 -1.207095 -0.700615 -1.254435 -0.200197   \n",
      "1  0.118997  1.192550  1.390108 -0.227345 -1.820100 -1.340123 -0.797827   \n",
      "2  1.766989  1.413203  1.779663  1.096476  1.666644  1.557943  0.920361   \n",
      "3 -0.555432 -0.382622  1.116322  1.436634  0.631923 -0.904914  0.429126   \n",
      "4 -0.106918 -0.710725 -0.667337 -0.719477 -0.486179 -0.771772 -0.545252   \n",
      "\n",
      "         X8        X9       X10  ...      X142      X143      X144      X145  \\\n",
      "0 -0.278388 -1.015858  0.309904  ... -1.422174 -2.296872 -2.104639 -2.363439   \n",
      "1 -0.390845 -0.101781 -0.248071  ...  0.725688  0.386470  0.080163  0.723598   \n",
      "2  1.434563  0.402589  0.177028  ... -0.445086 -0.401321 -0.250543 -0.003438   \n",
      "3 -0.260528 -1.693982 -1.811768  ... -0.047541  1.021219  0.463198  1.058450   \n",
      "4 -0.402469 -0.430549  0.013423  ...  0.231953 -0.233694 -0.078047  0.643347   \n",
      "\n",
      "       X146      X147      X148      X149      X150         Y  \n",
      "0 -1.707539 -0.346693 -0.107527  0.229568  1.037315  1.522912  \n",
      "1  0.464989  0.481666 -0.831270 -0.932613 -0.559191 -5.351373  \n",
      "2 -0.970914 -1.136299 -0.655550 -0.037692  1.311525  3.265122  \n",
      "3 -0.144056 -0.869222 -1.308777 -0.264276 -0.947465 -0.648769  \n",
      "4  1.589202  1.304518 -0.508744 -0.941539  0.256209 -2.252813  \n",
      "\n",
      "[5 rows x 151 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parameters\n",
    "N = 200\n",
    "p = 150  # must be >= 150\n",
    "\n",
    "# Build covariance matrix Œ£_ij = 0.5^{|i-j|} + 0.2 * I(i ‚â† j)\n",
    "indices = np.arange(p)\n",
    "Sigma = 0.5 ** np.abs(indices.reshape(-1, 1) - indices.reshape(1, -1))\n",
    "Sigma += 0.2 * (1 - np.eye(p))\n",
    "\n",
    "# Generate X ~ N(0, Œ£)\n",
    "X = np.random.multivariate_normal(mean=np.zeros(p), cov=Sigma, size=N)\n",
    "\n",
    "# Noise\n",
    "epsilon = np.random.normal(0, 1, size=N)\n",
    "\n",
    "# Compute Y = 2 X50 + 2 X100 + 4 X150 + noise\n",
    "Y = 2*X[:, 49] + 2*X[:, 99] + 4*X[:, 149] + epsilon\n",
    "\n",
    "# Build DataFrame with X1,...,Xp\n",
    "df = pd.DataFrame(X, columns=[f\"X{i+1}\" for i in range(p)])\n",
    "df[\"Y\"] = Y\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"dataset_scenario4.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as dataset_scenario4.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1207870-791f-4b24-8ef9-89591793fdc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\bahae\\\\Downloads\\\\ozone.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbahae\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mozone.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Lire le fichier .txt s√©par√© par des ;\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Sauvegarder en CSV\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\bahae\\\\Downloads\\\\ozone.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chemin vers ton fichier dans ton ordinateur\n",
    "input_path = r\"C:\\Users\\bahae\\Downloads\\ozone.txt\"\n",
    "output_path = r\"C:\\Users\\bahae\\Downloads\\ozone.csv\"\n",
    "\n",
    "# Lire le fichier .txt s√©par√© par des ;\n",
    "df = pd.read_csv(input_path, sep=\";\", encoding=\"utf-8\")\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Conversion termin√©e ! Le fichier ozone.csv est cr√©√© dans ton dossier Downloads.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2568c7c-014c-412e-9f20-67b2028a9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_path = r\"D:\\archive (1)\\parkinsons.data\"\n",
    "output_path = r\"D:\\parkinsons.csv\"\n",
    "\n",
    "df = pd.read_csv(input_path, sep=\",\", header=None)\n",
    "\n",
    "# Ajouter les noms de colonnes (officiel du dataset)\n",
    "df.columns = [\n",
    "    \"name\", \"MDVP:Fo(Hz)\", \"MDVP:Fhi(Hz)\", \"MDVP:Flo(Hz)\",\n",
    "    \"MDVP:Jitter(%)\", \"MDVP:Jitter(Abs)\", \"MDVP:RAP\", \"MDVP:PPQ\",\n",
    "    \"Jitter:DDP\", \"MDVP:Shimmer\", \"MDVP:Shimmer(dB)\", \"Shimmer:APQ3\",\n",
    "    \"Shimmer:APQ5\", \"MDVP:APQ\", \"Shimmer:DDA\", \"NHR\", \"HNR\",\n",
    "    \"RPDE\", \"DFA\", \"spread1\", \"spread2\", \"D2\", \"PPE\", \"status\"\n",
    "]\n",
    "\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"‚úî Conversion done ! File saved as parkinsons.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cf405-8795-47f8-84a9-9f6593906094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger ton fichier CSV qui contient la ligne dupliqu√©e\n",
    "df = pd.read_csv(\"parkinsons.csv\")\n",
    "\n",
    "# Supprimer la LIGNE qui a dupliqu√© les colonnes\n",
    "df = df.drop(index=0)  # si la ligne dupliqu√©e est la premi√®re\n",
    "# df = df.drop(index=1)  # sinon, si elle est la deuxi√®me\n",
    "\n",
    "# R√©initialiser l‚Äôindex proprement\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Sauvegarder un CSV propre\n",
    "df.to_csv(\"parkinsons_clean.csv\", index=False)\n",
    "\n",
    "print(\"‚úî Fichier corrig√© : parkinsons_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95afb44-c440-414d-9c01-467e4e699a05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
