{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e644b0a-0ece-4c4c-b041-3f8d20ea9168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers dans le dossier 'Data/' :\n",
      "==================================================\n",
      "1. .ipynb_checkpoints\n",
      "2. auto-mpg.csv\n",
      "3. BreastCanDT.csv\n",
      "4. concrete_data.csv\n",
      "5. dataset_scenario1.csv\n",
      "6. dataset_scenario2.csv\n",
      "7. dataset_scenario3.csv\n",
      "8. dataset_scenario4.csv\n",
      "9. HousingData.csv\n",
      "10. ozone.csv\n",
      "11. parkinsons.csv\n",
      "12. ReplicatedAcousticFeatures-ParkinsonDatabase.csv\n",
      "13. RLT_PROJECT.ipynb\n",
      "14. sonar.csv\n",
      "15. winequality-red.csv\n",
      "16. winequality-white.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Vérifier que le dossier data/ existe\n",
    "data_folder = 'Data'\n",
    "\n",
    "print(\"Fichiers dans le dossier 'Data/' :\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if os.path.exists(data_folder):\n",
    "    files = os.listdir(data_folder)\n",
    "    for i, file in enumerate(files, 1):\n",
    "        print(f\"{i}. {file}\")\n",
    "else:\n",
    "    print(\"Le dossier 'Data/' n'existe pas !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc8914d6-56fe-4eb5-b117-cf993ac303c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "AUGMENTATION DES FEATURES À 500\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      " HousingData\n",
      "======================================================================\n",
      "   Shape originale : (506, 14)\n",
      "   Valeurs manquantes détectées\n",
      "      Colonne 0 (numérique) : médiane = 0.25\n",
      "      Colonne 1 (numérique) : médiane = 0.00\n",
      "      Colonne 2 (numérique) : médiane = 9.69\n",
      "      Colonne 3 (binaire) : mode = 0.0\n",
      "      Colonne 6 (numérique) : médiane = 76.80\n",
      "      Colonne 12 (numérique) : médiane = 11.43\n",
      "   X : (506, 13), y : (506,)\n",
      "      Augmentation : 13 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\HousingData.csv\n",
      "\n",
      "======================================================================\n",
      " BreastCanDT\n",
      "======================================================================\n",
      "   Shape originale : (569, 33)\n",
      "   Target encode : {0: 'B', 1: 'M'}\n",
      "   Valeurs manquantes détectées\n",
      "      Colonne 31 : entièrement NaN → 0\n",
      "   X : (569, 32), y : (569,)\n",
      "      Augmentation : 32 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\BreastCanDT.csv\n",
      "\n",
      "======================================================================\n",
      " parkinsons\n",
      "======================================================================\n",
      "   Shape originale : (195, 24)\n",
      "   X : (195, 22), y : (195,)\n",
      "      Augmentation : 22 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\parkinsons.csv\n",
      "\n",
      "======================================================================\n",
      " sonar\n",
      "======================================================================\n",
      "   Shape originale : (207, 61)\n",
      "   Target encode : {0: 'M', 1: 'R'}\n",
      "   X : (207, 60), y : (207,)\n",
      "      Augmentation : 60 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\sonar.csv\n",
      "\n",
      "======================================================================\n",
      " winequality-white\n",
      "======================================================================\n",
      "   Shape originale : (4898, 12)\n",
      "   X : (4898, 11), y : (4898,)\n",
      "      Augmentation : 11 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\winequality-white.csv\n",
      "\n",
      "======================================================================\n",
      " winequality-red\n",
      "======================================================================\n",
      "   Shape originale : (1599, 12)\n",
      "   X : (1599, 11), y : (1599,)\n",
      "      Augmentation : 11 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\winequality-red.csv\n",
      "\n",
      "======================================================================\n",
      " ReplicatedAcousticFeatures-ParkinsonDatabase\n",
      "======================================================================\n",
      "   Shape originale : (240, 48)\n",
      "   X : (240, 46), y : (240,)\n",
      "      Augmentation : 46 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\ReplicatedAcousticFeatures-ParkinsonDatabase.csv\n",
      "\n",
      "======================================================================\n",
      " ozone\n",
      "======================================================================\n",
      "   Shape originale : (112, 14)\n",
      "   X : (112, 5), y : (112,)\n",
      "      Augmentation : 5 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\ozone.csv\n",
      "\n",
      "======================================================================\n",
      " concrete_data\n",
      "======================================================================\n",
      "   Shape originale : (1030, 9)\n",
      "   X : (1030, 8), y : (1030,)\n",
      "      Augmentation : 8 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\concrete_data.csv\n",
      "\n",
      "======================================================================\n",
      " auto_mpg\n",
      "======================================================================\n",
      "   Shape originale : (398, 9)\n",
      "   X : (398, 6), y : (398,)\n",
      "      Augmentation : 6 → 500 features\n",
      "    Sauvegardé : datasets_augmented\\auto_mpg.csv\n",
      "\n",
      "======================================================================\n",
      "RÉSUMÉ\n",
      "======================================================================\n",
      "\n",
      " Réussis : 10/10\n",
      "   HousingData                                        → (506, 500)\n",
      "   BreastCanDT                                        → (569, 500)\n",
      "   parkinsons                                         → (195, 500)\n",
      "   sonar                                              → (207, 500)\n",
      "   winequality-white                                  → (4898, 500)\n",
      "   winequality-red                                    → (1599, 500)\n",
      "   ReplicatedAcousticFeatures-ParkinsonDatabase       → (240, 500)\n",
      "   ozone                                              → (112, 500)\n",
      "   concrete_data                                      → (1030, 500)\n",
      "   auto_mpg                                           → (398, 500)\n",
      "\n",
      " Datasets sauvegardés dans : datasets_augmented/\n",
      "\n",
      " TERMINÉ !\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "============================================================================\n",
    "AUGMENTATION DES FEATURES À 500\n",
    "============================================================================\n",
    "Ce script charge chaque dataset et augmente le nombre de features à 500\n",
    "en créant des features synthétiques (signal + bruit, ratio 1:2)\n",
    "============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "TARGET_P = 500\n",
    "SEED = 42\n",
    "SIGNAL_NOISE_RATIO = 0.33\n",
    "OUTPUT_FOLDER = 'datasets_augmented'\n",
    "\n",
    "DATASETS_CONFIG = [\n",
    "    {'name': 'HousingData', 'filepath': 'Data/HousingData.csv', 'target_col': 'MEDV', 'sep': ','},\n",
    "    {'name': 'BreastCanDT', 'filepath': 'Data/BreastCanDT.csv', 'target_col': 'diagnosis', 'sep': ','},\n",
    "    {'name': 'parkinsons', 'filepath': 'data/parkinsons.csv', 'target_col': 'status', 'sep': ','},\n",
    "    {'name': 'sonar', 'filepath': 'data/sonar.csv', 'target_col': 'R', 'sep': ','},\n",
    "    {'name': 'winequality-white', 'filepath': 'Data/winequality-white.csv', 'target_col': 'quality', 'sep': ';'},\n",
    "    {'name': 'winequality-red', 'filepath': 'Data/winequality-red.csv', 'target_col': 'quality', 'sep': ','},\n",
    "    {'name': 'ReplicatedAcousticFeatures-ParkinsonDatabase',\n",
    "     'filepath': 'Data/ReplicatedAcousticFeatures-ParkinsonDatabase.csv',\n",
    "     'target_col': 'Status', 'sep': ','},\n",
    "    {'name': 'ozone', 'filepath': 'Data/ozone.csv', 'target_col': 'maxO3', 'sep': ','},\n",
    "    {'name': 'concrete_data', 'filepath': 'Data/concrete_data.csv',\n",
    "     'target_col': 'concrete_compressive_strength', 'sep': ','},\n",
    "    {'name': 'auto_mpg', 'filepath': 'Data/auto-mpg.csv', 'target_col': 'mpg', 'sep': ','}\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# FEATURE AUGMENTATION\n",
    "# ============================================================================\n",
    "\n",
    "def augment_features(X, target_p=TARGET_P, seed=SEED):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    n_samples, p_original = X.shape\n",
    "    n_new = target_p - p_original\n",
    "\n",
    "    if n_new <= 0:\n",
    "        print(f\"       Déjà {p_original} features\")\n",
    "        return X\n",
    "\n",
    "    print(f\"      Augmentation : {p_original} → {target_p} features\")\n",
    "\n",
    "    X_new = np.zeros((n_samples, n_new))\n",
    "\n",
    "    for i in range(n_new):\n",
    "        idx = np.random.randint(0, p_original)\n",
    "        signal = X[:, idx]\n",
    "\n",
    "        std = np.std(signal)\n",
    "        noise = np.random.normal(0, std if std > 0 else 1.0, n_samples)\n",
    "\n",
    "        X_new[:, i] = SIGNAL_NOISE_RATIO * signal + (1 - SIGNAL_NOISE_RATIO) * noise\n",
    "\n",
    "    return np.hstack([X, X_new])\n",
    "\n",
    "# ============================================================================\n",
    "# DATASET PROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "def process_dataset(config):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" {config['name']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(config['filepath'], sep=config['sep'])\n",
    "        print(f\"   Shape originale : {df.shape}\")\n",
    "\n",
    "        target_col = config['target_col']\n",
    "        y = df[target_col]\n",
    "        X_df = df.drop(columns=[target_col])\n",
    "\n",
    "        # garder seulement les features numériques\n",
    "        X_df = X_df.select_dtypes(include=[np.number])\n",
    "        original_column_names = X_df.columns.tolist()\n",
    "\n",
    "        # encoder la target si nécessaire\n",
    "        mapping = None\n",
    "        if y.dtype == 'object':\n",
    "            le = LabelEncoder()\n",
    "            y = le.fit_transform(y)\n",
    "            mapping = {int(i): str(v) for i, v in enumerate(le.classes_)}\n",
    "            print(f\"   Target encode : {mapping}\")\n",
    "        else:\n",
    "            y = y.values\n",
    "\n",
    "        # =======================\n",
    "        # IMPUTATION DES NaN\n",
    "        # =======================\n",
    "        if X_df.isna().any().any():\n",
    "            print(\"   Valeurs manquantes détectées\")\n",
    "\n",
    "            for col_idx in range(X_df.shape[1]):\n",
    "                col = X_df.iloc[:, col_idx]\n",
    "\n",
    "                if not col.isna().any():\n",
    "                    continue\n",
    "\n",
    "                unique_vals = col.dropna().unique()\n",
    "\n",
    "                # colonne entièrement NaN\n",
    "                if len(unique_vals) == 0:\n",
    "                    X_df.iloc[:, col_idx] = 0.0\n",
    "                    print(f\"      Colonne {col_idx} : entièrement NaN → 0\")\n",
    "                    continue\n",
    "\n",
    "                is_binary = set(unique_vals).issubset({0, 1, 0.0, 1.0})\n",
    "\n",
    "                if is_binary:\n",
    "                    mode_val = col.mode()[0]\n",
    "                    X_df.iloc[:, col_idx] = col.fillna(mode_val)\n",
    "                    print(f\"      Colonne {col_idx} (binaire) : mode = {mode_val}\")\n",
    "                else:\n",
    "                    median_val = col.median()\n",
    "                    X_df.iloc[:, col_idx] = col.fillna(median_val)\n",
    "                    print(f\"      Colonne {col_idx} (numérique) : médiane = {median_val:.2f}\")\n",
    "\n",
    "        X = X_df.values.astype(float)\n",
    "        y = y.astype(float)\n",
    "\n",
    "        print(f\"   X : {X.shape}, y : {y.shape}\")\n",
    "\n",
    "        # augmentation\n",
    "        X_augmented = augment_features(X)\n",
    "\n",
    "        os.makedirs(OUTPUT_FOLDER, exist_ok=True)\n",
    "\n",
    "        n_original = len(original_column_names)\n",
    "        n_synthetic = X_augmented.shape[1] - n_original\n",
    "\n",
    "        columns = original_column_names + [f\"synthetic_{i}\" for i in range(n_synthetic)]\n",
    "        output_df = pd.DataFrame(X_augmented, columns=columns)\n",
    "        output_df[target_col] = y\n",
    "\n",
    "        output_path = os.path.join(OUTPUT_FOLDER, f\"{config['name']}.csv\")\n",
    "        output_df.to_csv(output_path, index=False)\n",
    "\n",
    "        print(f\"    Sauvegardé : {output_path}\")\n",
    "\n",
    "        return {'name': config['name'], 'status': 'success',\n",
    "                'shape': X_augmented.shape, 'mapping': mapping}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ERREUR : {e}\")\n",
    "        return {'name': config['name'], 'status': 'failed', 'error': str(e)}\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*70)\n",
    "    print(\"AUGMENTATION DES FEATURES À 500\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    results = [process_dataset(cfg) for cfg in DATASETS_CONFIG]\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RÉSUMÉ\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    success = [r for r in results if r['status'] == 'success']\n",
    "    failed = [r for r in results if r['status'] == 'failed']\n",
    "\n",
    "    print(f\"\\n Réussis : {len(success)}/{len(results)}\")\n",
    "    for r in success:\n",
    "        print(f\"   {r['name']:<50s} → {r['shape']}\")\n",
    "\n",
    "    if failed:\n",
    "        print(f\"\\n Échoués : {len(failed)}\")\n",
    "        for r in failed:\n",
    "            print(f\"   {r['name']} : {r['error']}\")\n",
    "\n",
    "    print(f\"\\n Datasets sauvegardés dans : {OUTPUT_FOLDER}/\")\n",
    "    print(\"\\n TERMINÉ !\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fcae42-d9e8-4de0-a432-d6b4e9b7678f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
